{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0303d7a6",
   "metadata": {},
   "source": "# Boosted Tree Hyperparameter Search"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74ac0bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from startup import setup_environment\n",
    "from src.modeling.training import train_and_log\n",
    "from src.features.preprocessors import load_dataset, list_datasets\n",
    "from src.modeling.evaluate import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b590826",
   "metadata": {},
   "source": "### Datasets"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef2071",
   "metadata": {},
   "outputs": [],
   "source": "datasets = list_datasets()\nnames = ['dataset_v5_full_hourly_selected_rfecv', 'dataset_v5_full_hourly_selected_shap', \n         'dataset_v5_slim_hourly', 'dataset_v5_full_hourly']\ndata_ids = [\n    datasets[datasets['dataset_name'] == name].sort_values('version', ascending=False).iloc[0]['run_id']\n    for name in names \n    if (datasets['dataset_name'] == name).any()\n]\nprint(data_ids)\ndatasets"
  },
  {
   "cell_type": "markdown",
   "id": "995e6eb8",
   "metadata": {},
   "source": "### Regularisation configs"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b3d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg_configs = {\n",
    "    'Model A (moderate)': {\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.02,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': 8,\n",
    "        'min_child_samples': 50,\n",
    "        'subsample': 0.7,\n",
    "        'subsample_freq': 1,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'reg_alpha': 5.0,\n",
    "        'reg_lambda': 5.0,\n",
    "        'min_gain_to_split': 0.1,\n",
    "        'min_child_weight': 10,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "    },\n",
    "    'Model B (strong)': {\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 21,\n",
    "        'max_depth': 6,\n",
    "        'min_child_samples': 100,\n",
    "        'subsample': 0.5,\n",
    "        'subsample_freq': 1,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'reg_alpha': 10.0,\n",
    "        'reg_lambda': 10.0,\n",
    "        'min_gain_to_split': 0.5,\n",
    "        'min_child_weight': 20,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "    },\n",
    "    'Model C (very strong)': {\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.005,\n",
    "        'num_leaves': 15,\n",
    "        'max_depth': 4,\n",
    "        'min_child_samples': 200,\n",
    "        'subsample': 0.4,\n",
    "        'subsample_freq': 1,\n",
    "        'colsample_bytree': 0.4,\n",
    "        'reg_alpha': 20.0,\n",
    "        'reg_lambda': 20.0,\n",
    "        'min_gain_to_split': 1.0,\n",
    "        'min_child_weight': 50,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399073e6",
   "metadata": {},
   "source": "### Model configs"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47fb2fd",
   "metadata": {},
   "outputs": [],
   "source": "models = {\n    'LGBM': {\n        'class': lgb.LGBMRegressor,\n        'param_map': lambda p: {k: v for k, v in p.items() if k not in ['subsample_freq']},\n        'objective_map': {\n            'default': {'objective': 'regression', 'metric': 'rmse'},\n            'mae': {'objective': 'mae', 'metric': 'mae'},\n            'huber': {'objective': 'huber', 'metric': 'huber', 'alpha': 10.0}\n        }\n    },\n    'XGBoost': {\n        'class': xgb.XGBRegressor,\n        'param_map': lambda p: {\n            'n_estimators': p['n_estimators'],\n            'learning_rate': p['learning_rate'],\n            'max_depth': p['max_depth'],\n            'min_child_weight': p['min_child_samples'],\n            'subsample': p['subsample'],\n            'colsample_bytree': p['colsample_bytree'],\n            'reg_alpha': p['reg_alpha'],\n            'reg_lambda': p['reg_lambda'],\n            'gamma': p['min_gain_to_split'],\n            'verbosity': 0\n        },\n        'objective_map': {\n            'default': {'objective': 'reg:squarederror', 'eval_metric': 'rmse'},\n            'mae': {'objective': 'reg:absoluteerror', 'eval_metric': 'mae'},\n            'huber': {'objective': 'reg:pseudohubererror', 'eval_metric': 'mae', 'huber_slope': 10.0}\n        }\n    },\n    'CatBoost': {\n        'class': cb.CatBoostRegressor,\n        'param_map': lambda p: {\n            'iterations': p['n_estimators'],\n            'learning_rate': p['learning_rate'],\n            'depth': p['max_depth'],\n            'min_child_samples': p['min_child_samples'],\n            'subsample': p['subsample'],\n            'rsm': p['colsample_bytree'],\n            'l2_leaf_reg': p['reg_lambda'],\n            'verbose': False\n        },\n        'objective_map': {\n            'default': {'loss_function': 'RMSE'},\n            'mae': {'loss_function': 'MAE'},\n            'huber': {'loss_function': 'Huber:delta=10'}\n        }\n    }\n}"
  },
  {
   "cell_type": "markdown",
   "id": "489e1018",
   "metadata": {},
   "source": "#### Restart logic"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f6cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_from = (data_ids[0], 'CatBoost', 'Model A (moderate)', 'default')  # adjust as needed\n",
    "resume = True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c791a5",
   "metadata": {},
   "source": [
    "## Main model loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb63c9",
   "metadata": {},
   "outputs": [],
   "source": "all_run_ids = []\n\nfor data_id in data_ids:\n    for model_name, model_info in models.items():\n        for config_name, base_params in reg_configs.items():\n            model_params = model_info['param_map'](base_params)\n            config_letter = config_name[6]\n\n            for obj_name, obj_params in model_info['objective_map'].items():\n                current = (data_id, model_name, config_name, obj_name)\n                if resume:\n                    if current == start_from:\n                        resume = False\n                    else:\n                        continue\n\n                full_params = {**model_params, **obj_params}\n                model = model_info['class'](**full_params)\n\n                run_name = f\"{model_name}_hourly_{config_letter}_{obj_name}\"\n                description = (f\"{model_name} hourly global model, \"\n                               f\"regularisation {config_name}, loss={obj_name}\")\n                tags = {\n                    \"model_family\": \"boosted_tree\",\n                    \"model\": model_name,\n                    \"regularisation_level\": config_letter,\n                    \"loss\": obj_name,\n                    \"dataset_id\": data_id\n                }\n\n                run_id = train_and_log(\n                    dataset_run_id=data_id,\n                    model=model,\n                    model_name=f\"{model_name}_reg_{config_letter}\",\n                    target_transform=\"none\",\n                    experiment=f\"{model_name}_hourly\",\n                    run_name=run_name,\n                    description=description,\n                    tags=tags,\n                    group_size=24,\n                    y_baseline=None,\n                    test_size=0.1,\n                    weight_half_life=730\n                )\n                all_run_ids.append(run_id)"
  },
  {
   "cell_type": "markdown",
   "id": "7b3abab3",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6114d",
   "metadata": {},
   "outputs": [],
   "source": "import mlflow\nimport pandas as pd\n\ndef get_run_metadata(run_id: str) -> dict:\n    \"\"\"Return metadata for a given MLflow run as a flat dictionary.\"\"\"\n    run = mlflow.get_run(run_id)\n    info = run.info\n    return {\n        \"run_name\": info.run_name,\n        \"run_id\": info.run_id,\n        \"experiment_id\": info.experiment_id,\n        \"status\": info.status,\n        \"start_time\": pd.Timestamp(info.start_time, unit=\"ms\", tz=\"UTC\"),\n        \"end_time\": pd.Timestamp(info.end_time, unit=\"ms\", tz=\"UTC\") if info.end_time else None,\n        \"artifact_uri\": info.artifact_uri,\n        \"params\": run.data.params,\n        \"metrics\": run.data.metrics,\n        \"tags\": run.data.tags,\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f41f17",
   "metadata": {},
   "outputs": [],
   "source": "rows = []\nfor run_id in all_run_ids:\n    run = mlflow.get_run(run_id)\n    rows.append({\n        \"run_name\": run.info.run_name,\n        \"dataset_name\": run.data.params.get(\"dataset_name\"),\n        \"model\": run.data.tags.get(\"model\"),\n        \"regularisation_level\": run.data.tags.get(\"regularisation_level\"),\n        \"loss\": run.data.tags.get(\"loss\"),\n        \"rmse\": run.data.metrics.get(\"rmse\"),\n        \"mae\": run.data.metrics.get(\"mae\"),\n        \"me\": run.data.metrics.get(\"me\"),\n        \"r2\": run.data.metrics.get(\"r2\"),\n    })\n\nresults_df = pd.DataFrame(rows)\nresults_df"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d6eb360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>me</th>\n",
       "      <th>r2</th>\n",
       "      <th>grouping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>22.9639</td>\n",
       "      <td>14.0237</td>\n",
       "      <td>0.9427</td>\n",
       "      <td>0.7965</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>23.1844</td>\n",
       "      <td>13.6261</td>\n",
       "      <td>1.6908</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>22.4497</td>\n",
       "      <td>13.4348</td>\n",
       "      <td>1.8729</td>\n",
       "      <td>0.8054</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>21.4566</td>\n",
       "      <td>13.0190</td>\n",
       "      <td>1.8479</td>\n",
       "      <td>0.8226</td>\n",
       "      <td>regularisation_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>22.3889</td>\n",
       "      <td>13.3846</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.8067</td>\n",
       "      <td>regularisation_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>24.7819</td>\n",
       "      <td>14.7797</td>\n",
       "      <td>1.5214</td>\n",
       "      <td>0.7605</td>\n",
       "      <td>regularisation_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>default</td>\n",
       "      <td>22.4109</td>\n",
       "      <td>13.9161</td>\n",
       "      <td>4.0216</td>\n",
       "      <td>0.8066</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>huber</td>\n",
       "      <td>24.2556</td>\n",
       "      <td>14.5683</td>\n",
       "      <td>0.3438</td>\n",
       "      <td>0.7695</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mae</td>\n",
       "      <td>21.9609</td>\n",
       "      <td>12.6990</td>\n",
       "      <td>-0.0268</td>\n",
       "      <td>0.8137</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dataset_v5_full_hourly</td>\n",
       "      <td>22.8712</td>\n",
       "      <td>13.6448</td>\n",
       "      <td>1.9377</td>\n",
       "      <td>0.7966</td>\n",
       "      <td>dataset_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dataset_v5_full_hourly_selected_rfecv</td>\n",
       "      <td>23.2341</td>\n",
       "      <td>14.1361</td>\n",
       "      <td>0.3247</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>dataset_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dataset_v5_full_hourly_selected_shap</td>\n",
       "      <td>22.6762</td>\n",
       "      <td>13.5953</td>\n",
       "      <td>1.2605</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>dataset_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dataset_v5_slim_hourly</td>\n",
       "      <td>22.9606</td>\n",
       "      <td>13.8071</td>\n",
       "      <td>1.5142</td>\n",
       "      <td>0.7950</td>\n",
       "      <td>dataset_name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    index     rmse      mae      me      r2  \\\n",
       "0                                CatBoost  22.9639  14.0237  0.9427  0.7965   \n",
       "1                                    LGBM  23.1844  13.6261  1.6908  0.7881   \n",
       "2                                 XGBoost  22.4497  13.4348  1.8729  0.8054   \n",
       "3                                       A  21.4566  13.0190  1.8479  0.8226   \n",
       "4                                       B  22.3889  13.3846  0.9693  0.8067   \n",
       "5                                       C  24.7819  14.7797  1.5214  0.7605   \n",
       "6                                 default  22.4109  13.9161  4.0216  0.8066   \n",
       "7                                   huber  24.2556  14.5683  0.3438  0.7695   \n",
       "8                                     mae  21.9609  12.6990 -0.0268  0.8137   \n",
       "9                  dataset_v5_full_hourly  22.8712  13.6448  1.9377  0.7966   \n",
       "10  dataset_v5_full_hourly_selected_rfecv  23.2341  14.1361  0.3247  0.7917   \n",
       "11   dataset_v5_full_hourly_selected_shap  22.6762  13.5953  1.2605  0.7998   \n",
       "12                 dataset_v5_slim_hourly  22.9606  13.8071  1.5142  0.7950   \n",
       "\n",
       "                grouping  \n",
       "0                  model  \n",
       "1                  model  \n",
       "2                  model  \n",
       "3   regularisation_level  \n",
       "4   regularisation_level  \n",
       "5   regularisation_level  \n",
       "6                   loss  \n",
       "7                   loss  \n",
       "8                   loss  \n",
       "9           dataset_name  \n",
       "10          dataset_name  \n",
       "11          dataset_name  \n",
       "12          dataset_name  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupings = []\n",
    "groupings.append(results_df.groupby('model').agg({'rmse': 'mean', 'mae': 'mean', 'me': 'mean', 'r2': 'mean'}).round(4).assign(grouping='model'))\n",
    "groupings.append(results_df.groupby('regularisation_level').agg({'rmse': 'mean', 'mae': 'mean', 'me': 'mean', 'r2': 'mean'}).round(4).assign(grouping='regularisation_level'))\n",
    "groupings.append(results_df.groupby('loss').agg({'rmse': 'mean', 'mae': 'mean', 'me': 'mean', 'r2': 'mean'}).round(4).assign(grouping='loss'))\n",
    "groupings.append(results_df.groupby('dataset_name').agg({'rmse': 'mean', 'mae': 'mean', 'me': 'mean', 'r2': 'mean'}).round(4).assign(grouping='dataset_name'))\n",
    "avg_df = pd.concat(groupings).reset_index()\n",
    "avg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba046bd",
   "metadata": {},
   "source": [
    "## Random search for refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a85a21",
   "metadata": {},
   "outputs": [],
   "source": "best_data_id = '247ccd98f2614cc5aa0bf834c1f1835e'\n\nparam_ranges = {\n    'n_estimators': (800, 1200),\n    'learning_rate': (0.005, 0.03),\n    'num_leaves': (15, 40),\n    'max_depth': (4, 10),\n    'min_child_samples': (30, 120),\n    'subsample': (0.4, 0.8),\n    'colsample_bytree': (0.4, 0.8),\n    'reg_alpha': (2.0, 12.0),\n    'reg_lambda': (2.0, 12.0),\n    'min_gain_to_split': (0.05, 0.7),\n    'min_child_weight': (5, 25),\n}\n\nweight_half_life_range = (365, 365 * 3)"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1cab24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LGBM': {\n",
    "        'class': lgb.LGBMRegressor,\n",
    "        'param_map': lambda p: {**p, 'objective': 'mae', 'metric': 'mae', \n",
    "                                 'verbosity': -1, 'boosting_type': 'gbdt'}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'class': xgb.XGBRegressor,\n",
    "        'param_map': lambda p: {\n",
    "            'n_estimators': p['n_estimators'],\n",
    "            'learning_rate': p['learning_rate'],\n",
    "            'max_depth': p['max_depth'],\n",
    "            'min_child_weight': p['min_child_samples'],\n",
    "            'subsample': p['subsample'],\n",
    "            'colsample_bytree': p['colsample_bytree'],\n",
    "            'reg_alpha': p['reg_alpha'],\n",
    "            'reg_lambda': p['reg_lambda'],\n",
    "            'gamma': p['min_gain_to_split'],\n",
    "            'objective': 'reg:absoluteerror',\n",
    "            'eval_metric': 'mae',\n",
    "            'verbosity': 0\n",
    "        }\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'class': cb.CatBoostRegressor,\n",
    "        'param_map': lambda p: {\n",
    "            'iterations': p['n_estimators'],\n",
    "            'learning_rate': p['learning_rate'],\n",
    "            'depth': p['max_depth'],\n",
    "            'min_child_samples': p['min_child_samples'],\n",
    "            'subsample': p['subsample'],\n",
    "            'rsm': p['colsample_bytree'],\n",
    "            'l2_leaf_reg': p['reg_lambda'],\n",
    "            'loss_function': 'MAE',\n",
    "            'verbose': False\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ffcb9",
   "metadata": {},
   "source": "### Random search loop"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c0f94",
   "metadata": {},
   "outputs": [],
   "source": "np.random.seed(123)\nn_trials = 30\nrefinement_run_ids = []\n\nint_params = {'n_estimators', 'num_leaves', 'max_depth', 'min_child_samples', 'min_child_weight'}\n\nfor trial in range(n_trials):\n    sampled_lgb_params = {\n        key: np.random.randint(int(round(low)), int(round(high)) + 1)\n        if key in int_params else np.random.uniform(low, high)\n        for key, (low, high) in param_ranges.items()\n    }\n\n    whl_low, whl_high = weight_half_life_range\n    weight_half_life = np.random.randint(whl_low, whl_high + 1)\n\n    for model_name, model_info in models.items():\n        model_params = model_info['param_map'](sampled_lgb_params)\n        model = model_info['class'](**model_params)\n\n        run_name = f\"{model_name}_rand_trial_{trial:02d}\"\n        tags = {\n            \"model_family\": \"boosted_tree\",\n            \"model\": model_name,\n            \"strategy\": \"hourly_global\",\n            \"loss\": \"mae\",\n            \"refinement\": \"random_search\",\n            \"trial\": str(trial)\n        }\n\n        run_id = train_and_log(\n            dataset_run_id=best_data_id,\n            model=model,\n            model_name=f\"{model_name}_rand_trial_{trial:02d}\",\n            target_transform=\"none\",\n            experiment=f\"{model_name}_hourly\",\n            run_name=run_name,\n            description=f\"{model_name} random search trial {trial}\",\n            tags=tags,\n            group_size=24,\n            y_baseline=None,\n            test_size=0.1,\n            weight_half_life=730\n        )\n        refinement_run_ids.append(run_id)\n\nprint(f\"Completed {n_trials * len(models)} random search runs.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}