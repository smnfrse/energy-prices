{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Blend Selection\n",
    "\n",
    "Starting from the best single model (by holdout MAE), incrementally add models\n",
    "and report whether each addition improves the inverse-MAE-weighted blend.\n",
    "Uses the production `blend_config.json` and the same methodology as `train_and_blend()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from startup import PROJ_ROOT\n",
    "\n",
    "import json\n",
    "\n",
    "import joblib\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "from src.config import MLFLOW_TRACKING_URI\n",
    "from src.features.preprocessors import load_dataset\n",
    "from src.modeling.blend import (\n",
    "    BLEND_CONFIG_PATH,\n",
    "    PRODUCTION_DIR,\n",
    "    _compute_inverse_mae_weights,\n",
    "    _flatten_daily_to_hourly,\n",
    "    _flatten_y_true,\n",
    ")\n",
    "from src.config.modeling import BLEND_HOLDOUT_DAYS\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "with open(BLEND_CONFIG_PATH) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "holdout_days = config[\"holdout_days\"]\n",
    "models_info = config[\"models\"]\n",
    "print(f\"Loaded {len(models_info)} models, holdout_days={holdout_days}\")\n",
    "for m in models_info:\n",
    "    print(f\"  {m['name']:20s}  MAE={m['holdout_mae']:.2f}  w={m['weight']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and generate holdout predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets (cached by dataset_run_id)\n",
    "dataset_cache: dict[str, tuple] = {}\n",
    "for info in models_info:\n",
    "    rid = info[\"dataset_run_id\"]\n",
    "    if rid not in dataset_cache:\n",
    "        print(f\"Loading dataset {rid[:8]}...\")\n",
    "        X, y_df, _ = load_dataset(run_id=rid)\n",
    "        dataset_cache[rid] = (X, y_df.values)\n",
    "\n",
    "# Generate holdout predictions per model\n",
    "model_names = []\n",
    "holdout_preds = {}  # name -> hourly preds array\n",
    "holdout_maes = {}   # name -> scalar MAE\n",
    "ref_y = None        # common hourly y_true (from first model's holdout)\n",
    "\n",
    "for info in models_info:\n",
    "    name = info[\"name\"]\n",
    "    group_size = info[\"group_size\"]\n",
    "    X, y = dataset_cache[info[\"dataset_run_id\"]]\n",
    "\n",
    "    holdout_rows = holdout_days * group_size\n",
    "    split_idx = len(X) - holdout_rows\n",
    "    X_holdout = X.iloc[split_idx:]\n",
    "    y_holdout = y[split_idx:]\n",
    "\n",
    "    pipeline = joblib.load(PRODUCTION_DIR / info[\"file\"])\n",
    "    y_pred = pipeline.predict(X_holdout)\n",
    "\n",
    "    y_pred_flat = _flatten_daily_to_hourly(y_pred)\n",
    "    y_true_flat = _flatten_y_true(y_holdout, group_size)\n",
    "\n",
    "    # Align lengths\n",
    "    min_len = min(len(y_pred_flat), len(y_true_flat))\n",
    "    y_pred_flat = y_pred_flat[:min_len]\n",
    "    y_true_flat = y_true_flat[:min_len]\n",
    "\n",
    "    holdout_preds[name] = y_pred_flat\n",
    "    holdout_maes[name] = mean_absolute_error(y_true_flat, y_pred_flat)\n",
    "    model_names.append(name)\n",
    "\n",
    "    if ref_y is None:\n",
    "        ref_y = y_true_flat\n",
    "\n",
    "    print(f\"  {name:20s}  holdout MAE={holdout_maes[name]:.4f}  shape={y_pred_flat.shape}\")\n",
    "\n",
    "# Align all predictions to common length (inner join on hourly index)\n",
    "common_len = min(len(ref_y), *(len(p) for p in holdout_preds.values()))\n",
    "ref_y = ref_y[:common_len]\n",
    "for name in model_names:\n",
    "    holdout_preds[name] = holdout_preds[name][:common_len]\n",
    "\n",
    "print(f\"\\nCommon holdout length: {common_len} hours ({common_len // 24} days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_metrics(names: list[str]) -> dict:\n",
    "    \"\"\"Compute blend metrics for a subset of models using inverse-MAE weights.\"\"\"\n",
    "    maes = np.array([holdout_maes[n] for n in names])\n",
    "    weights = _compute_inverse_mae_weights(maes)\n",
    "    preds_matrix = np.column_stack([holdout_preds[n] for n in names])\n",
    "    y_blend = preds_matrix @ weights\n",
    "    return {\n",
    "        \"mae\": mean_absolute_error(ref_y, y_blend),\n",
    "        \"rmse\": float(np.sqrt(np.mean((ref_y - y_blend) ** 2))),\n",
    "        \"r2\": float(r2_score(ref_y, y_blend)),\n",
    "        \"weights\": dict(zip(names, weights.round(4))),\n",
    "    }\n",
    "\n",
    "\n",
    "# Rank models by individual holdout MAE (best first)\n",
    "ranked = sorted(model_names, key=lambda n: holdout_maes[n])\n",
    "\n",
    "print(\"Individual model ranking (by holdout MAE):\")\n",
    "print(f\"{'Rank':<6}{'Model':<22}{'MAE':>10}\")\n",
    "print(\"-\" * 38)\n",
    "for i, name in enumerate(ranked, 1):\n",
    "    print(f\"{i:<6}{name:<22}{holdout_maes[name]:>10.4f}\")\n",
    "\n",
    "# Greedy forward selection\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Greedy Forward Selection\")\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"{'Step':<6}{'Added Model':<22}{'Blend MAE':>12}\"\n",
    "    f\"{'Delta':>10}{'Blend RMSE':>12}{'R2':>8}{'N':>4}\"\n",
    ")\n",
    "print(\"-\" * 74)\n",
    "\n",
    "selected = []\n",
    "remaining = list(ranked)\n",
    "prev_mae = None\n",
    "results = []\n",
    "\n",
    "for step in range(1, len(ranked) + 1):\n",
    "    # Try adding each remaining model and pick the one that gives best blend MAE\n",
    "    best_candidate = None\n",
    "    best_metrics = None\n",
    "\n",
    "    for candidate in remaining:\n",
    "        trial = selected + [candidate]\n",
    "        m = blend_metrics(trial)\n",
    "        if best_metrics is None or m[\"mae\"] < best_metrics[\"mae\"]:\n",
    "            best_candidate = candidate\n",
    "            best_metrics = m\n",
    "\n",
    "    selected.append(best_candidate)\n",
    "    remaining.remove(best_candidate)\n",
    "\n",
    "    delta = best_metrics[\"mae\"] - prev_mae if prev_mae is not None else 0.0\n",
    "    delta_str = f\"{delta:+.4f}\" if prev_mae is not None else \"--\"\n",
    "    marker = \" *\" if prev_mae is not None and delta < 0 else \"\"\n",
    "\n",
    "    print(\n",
    "        f\"{step:<6}{best_candidate:<22}{best_metrics['mae']:>12.4f}\"\n",
    "        f\"{delta_str:>10}{best_metrics['rmse']:>12.4f}\"\n",
    "        f\"{best_metrics['r2']:>8.4f}{len(selected):>4}{marker}\"\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"step\": step,\n",
    "        \"added\": best_candidate,\n",
    "        \"blend_mae\": best_metrics[\"mae\"],\n",
    "        \"delta_mae\": delta if prev_mae is not None else None,\n",
    "        \"blend_rmse\": best_metrics[\"rmse\"],\n",
    "        \"blend_r2\": best_metrics[\"r2\"],\n",
    "        \"n_models\": len(selected),\n",
    "        \"models\": list(selected),\n",
    "        \"weights\": best_metrics[\"weights\"],\n",
    "    })\n",
    "    prev_mae = best_metrics[\"mae\"]\n",
    "\n",
    "print(\"\\n* = improvement over previous step\")\n",
    "\n",
    "# Find optimal subset\n",
    "best_step = min(results, key=lambda r: r[\"blend_mae\"])\n",
    "print(f\"\\nBest blend: step {best_step['step']} with {best_step['n_models']} models\")\n",
    "print(f\"  MAE  = {best_step['blend_mae']:.4f}\")\n",
    "print(f\"  RMSE = {best_step['blend_rmse']:.4f}\")\n",
    "print(f\"  R2   = {best_step['blend_r2']:.4f}\")\n",
    "print(f\"  Models: {best_step['models']}\")\n",
    "print(f\"  Weights: {best_step['weights']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "summary = pd.DataFrame(results)\n",
    "summary = summary[[\"step\", \"added\", \"n_models\", \"blend_mae\", \"delta_mae\", \"blend_rmse\", \"blend_r2\"]]\n",
    "summary[\"delta_mae\"] = summary[\"delta_mae\"].map(lambda x: f\"{x:+.4f}\" if x is not None else \"--\")\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}